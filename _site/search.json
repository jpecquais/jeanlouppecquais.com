[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Mixage Ambisonique dans REAPER - Introduction\n\n\nUne Alternative au Dolby Atmos\n\n\n\naudio\n\n\nspatialisation\n\n\nambisonie\n\n\n\n\n\n\n\n\n\n13 mars 2025\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\n\n\n\n\nRéseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare\n\n\nPt.II - Mise en place du dispositif\n\n\n\ndsp\n\n\nguitar\n\n\ndeconvolution\n\n\n\n\n\n\n\n\n\n3 nov. 2024\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\n\n\n\n\nRéseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare\n\n\nPt.I - Enoncé du problème\n\n\n\ndsp\n\n\nguitar\n\n\n\n\n\n\n\n\n\n16 oct. 2024\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jean-Loup Pecquais",
    "section": "",
    "text": "À propos\nJean-Loup Pecquais est ingénieur du son, spécialisé dans le son immersif, l’informatique audio et le traitement du signal sonore. Il travaille actuellement comme développeur et ingénieur applicatif chez Harman, et enseigne à l’ENS Louis Lumière.\nIl est également guitariste et membre des groupes Outwards, Pompéi et Burger Bang."
  },
  {
    "objectID": "training/initiation-3D-sonore/index.html",
    "href": "training/initiation-3D-sonore/index.html",
    "title": "Initiation à la 3D sonore",
    "section": "",
    "text": "Cette formation, intitulée “Initiation à la 3D Sonore,” est une immersion de cinq jours dans l’univers captivant de la création sonore spatialisée. Conçue par Jean-Marc Duchenne, elle est désormais proposée par le centre de formation Whiti Audio. Au cours de cette formation, vous explorerez l’évolution de la création sonore depuis le XXème siècle, des pionniers tels que Xenakis et Stockhausen jusqu’aux dernières avancées en réalité virtuelle et augmentée.\nLe programme complet de la formation englobe les bases de la perception audio spatiale, les formats de réalisation et de diffusion sonore, les techniques de capture sonore, les méthodes de traitement spatial, ainsi que les environnements logiciels et matériels pour la production immersive. Vous découvrirez les nuances de la diffusion en haute résolution, de l’ambisonique, du mixage orienté objets, du binaural et bien plus encore. Préparez-vous à repousser les limites de la perception sonore en vous inscrivant à la formation “Initiation à la 3D Sonore.” Explorez un monde sonore en trois dimensions et plongez dans l’avenir passionnant de la création sonore spatiale."
  },
  {
    "objectID": "training/informatique-audio/index.html",
    "href": "training/informatique-audio/index.html",
    "title": "Informatique audio",
    "section": "",
    "text": "Le cours “Informatique Audio”, dispensé sur trois jours, constitue une exploration approfondie de l’intersection entre l’informatique et les métiers du son. Dispensé aux étudiants deÒ première année de l’École Nationale Supérieure Louis Lumière, il a pour objectif de fournir aux étudiants une base solide dans ce domaine passionnant.\nCe cours commence par retracer l’origine de l’informatique, repartant de technologies simples pour expliquer la complexité des systèmes contemporains. Ensuite, les étudiants explorent les bases en architecture informatique, acquérant ainsi une compréhension des fondements des systèmes informatiques et de leur fonctionnement, essentielle pour maîtriser les outils audionumériques actuels.\nUne part significative du cours se consacre à l’étude des systèmes informatiques professionnels et dédiés au traitement de son en temps réel. Cette section inclut l’exploration de matériels propriétaires dédiés, de solutions généralistes et de systèmes embarqués, offrant aux étudiants un tour d’horizon de ces technologies cruciales pour les métiers du son.\nEnfin, le cours présente des études de cas réelles de déploiement de systèmes informatiques, que ce soit dans des studios d’enregistrement ou des événements live. Ces exemples concrets permettent aux étudiants de voir comment les principes théoriques s’appliquent dans la pratique, renforçant ainsi leur compréhension globale de l’informatique appliquée à audio."
  },
  {
    "objectID": "training/initiation-programmation/index.html",
    "href": "training/initiation-programmation/index.html",
    "title": "Initiation à la programmation",
    "section": "",
    "text": "Le cours « Initiation à la programmation pour les métiers du son » est destiné aux étudiants de deuxième année de l’ENS Louis Lumière. D’une durée de trois jours, il se concentre principalement sur des travaux pratiques.\nLes participants auront l’occasion d’apprendre un langage de programmation haut niveau et impératif, en commençant par la création de scripts pour le logiciel REAPER. Ce cours se termine par la réalisation de traitements sur le signal sonore directement exploitable dans un Digital Audio Workstation (DAW).\nAu terme de ces trois jours, les étudiants seront prêts à intégrer des éléments de programmation dans leur pratique professionnelle, leur ouvrant ainsi de nouvelles possibilités dans leurs futurs domaines d’expertise."
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt1/index.html",
    "href": "posts/reseau-neuronne-deconvolution-pt1/index.html",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "",
    "text": "image générée par IA\nÀ l’heure où j’écris cet article, la simulation d’équipements “audiomusicaux” repose de plus en plus sur l’entraînement de réseaux de neurones 1, souvent grâce à l’apprentissage profond (deep learning) 2. Cette méthode est particulièrement séduisante, car elle ne nécessite aucune connaissance préalable sur l’équipement à modéliser. On parle alors de simulation “boîte noire” (black box) : seul le résultat final compte, peu importe comment il est produit.\nMe concernant, je suis intrigué par la capacité de cette technologie à fournir des simulations convaincantes d’amplificateurs pour guitare électrique. Plus particulièrement, la modélisation de l’étage d’amplification de puissance est cruciale pour remplacer un amplificateur sur scène sans perdre son effet sur le signal. Rappelons que les amplificateurs de guitare sont, par conception, particulièrement non linéaires, que ce soit dans leur réponse en fréquence ou dans l’ajout de distorsion harmonique.\nLe second aspect intéressant dans l’apprentissage profond est la possibilité de modéliser ses équipements. Voici alors la situation idéale : laissez votre ampli à lampe préféré à la maison, faites en une simple “emprunte” et emmener seulement une petite “boîte noire” numérique sur scène. Sur le papier, l’idée semble convaincante.\nLes difficultés commencent lorsque l’on souhaite réaliser ses propres captures. En règle générale, la procédure est similaire pour la plupart des fabricants de telles simulations : on émet un signal dans notre matériel, on enregistre la sortie du périphérique, puis on entraîne le réseau de neurones en lui injectant les deux signaux, soit sur un appareil spécifique, soit en ligne, sur une plateforme telle que Google Colab, par exemple.\nCependant, il faut bien distinguer plusieurs types d’équipements :\nDans le premier cas, l’acquisition pose moins de difficulté. On sort le signal de son interface audio, on récupère la sortie du périphérique dans une entrée en ligne ou un préamplificateur, et le tour est joué.\nDans le second cas, les choses se corsent. Un ampli de puissance à lampe possède un transformateur de sortie qui doit impérativement voir une charge particulière à ses bornes, sinon, on risque la défaillance de l’équipement. De plus, le niveau de sortie est tel qu’il est inimaginable de câbler la sortie d’un amplificateur de puissance dans une entrée en ligne. On a alors besoin d’un équipement qui va à la fois jouer le rôle de charge passive du haut-parleur (loadbox) et d’atténuateur vers un niveau en ligne.\nDans cette famille d’équipement, que nous appellerons simplement loadbox, on distingue deux catégories principales:\nCes dernières sont les plus “réalistes” par rapport au comportement d’un haut-parleur réel, qui, lui-même, ne possède pas une impédance d’entrée constante en fonction de la fréquence.\nSi les loadbox à charges purement résistives sont relativement abordables, les autres le sont beaucoup moins. C’est donc un investissement conséquent à rajouter en plus de son équipement à modéliser et de son équipement permettant de réaliser le traitement du signal à partir d’un modèle issu d’un apprentissage profond.\nQui plus est, cette approche tend à considérer le haut-parleur guitare comme un transducteur purement linéaire. Typiquement, une chaîne de traitement numérique “moderne” pour guitariste inclut une simulation par réseau de neurones pour la partie amplification et une opération de convolution pour la simulation du haut-parleur (convolution 4 réalisée avec la réponse impulsionnelle faite d’un haut-parleur). Rappelons ici que l’opération de convolution est une opération strictement linéaire. Cette méthode minimise ainsi le rôle du haut-parleur dans les non-linéarités introduites sur le signal.\nLa question est donc: comment pourrait-on faire mieux, ou, du moins, autrement ?\nLa méthode proposée ici est de ne pas court-circuiter le haut-parleur dans l’étape de la mesure. Ainsi, au lieu de relier l’amplificateur de puissance à une loadbox, ce dernier est normalement connecté à son/ses haut-parleur(s). Dès lors, on enregistre simplement ce qu’émet le haut-parleur à l’aide d’un microphone.\nDe prime à bord, on inclut donc les non-linéarités du haut-parleur et ses interactions avec l’amplificateur de puissance, mais aussi la réponse en fréquence du transducteur ! On perd alors la flexibilité de pouvoir changer “virtuellement” de haut-parleur en changeant de réponse impulsionnelle dans un moteur de convolution.\nLa solution proposée est donc de réaliser, en plus de la mesure nécessaire à l’entraînement du réseau de neurones, la réponse impulsionnelle du haut-parleur, puis de déconvoluer 5 cette réponse impulsionnelle des enregistrements réalisés en vue de l’apprentissage profond. Afin de ne pas altérer la réponse en fréquence de l’amplificateur, on réalise la réponse impulsionnelle avec un autre amplificateur, que l’on sait suffisamment linéaire.\nQuels sont les avantages de cette méthode ? Premièrement, il semble que l’on “extrait” ici plus d’information sur le comportement de l’amplificateur que l’on cherche à modéliser. Deuxièmement, un microphone de mesure et un amplificateur relativement “transparent” sont des équipements moins onéreux qu’une loadbox à charge variable.\nDans le prochain article, nous aborderons dans le détail le protocole de mesure ainsi que les enjeux entourant la déconvolution."
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt1/index.html#footnotes",
    "href": "posts/reseau-neuronne-deconvolution-pt1/index.html#footnotes",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nEn apprentissage automatique (machine learning), un réseau de neurones (également appelé réseau de neurones artificiels ou réseau neuronal) est un modèle inspiré par la structure et le fonctionnement des réseaux neuronaux biologiques dans les cerveaux des animaux. Les réseaux de neurones artificiels sont utilisés pour diverses tâches, notamment la modélisation prédictive, le contrôle adaptatif et la résolution de problèmes en intelligence artificielle. Ils peuvent apprendre de l’expérience et tirer des conclusions à partir d’un ensemble complexe et apparemment non lié d’informations.↩︎\nL’apprentissage profond est une sous-catégorie de l’apprentissage automatique qui utilise des réseaux de neurones avec de nombreuses couches pour modéliser des structures de données complexes.↩︎\nL’impédance est une mesure de l’opposition d’un circuit électrique au passage d’un courant alternatif. Elle est une combinaison de la résistance et de la réactance.↩︎\nPour les lectrices et lecteurs moins aguerris en traitement du signal, l’opération de convolution est d’une importance majeure dans la matière. Voici un bon point de départ.↩︎\nLa déconvolution est une opération mathématique utilisée pour inverser les effets de la convolution, permettant de retrouver le signal d’origine à partir d’un signal convolué.↩︎"
  },
  {
    "objectID": "music.html",
    "href": "music.html",
    "title": "Musique",
    "section": "",
    "text": "Outwards\n\n\nEntre rock alternatif et rock progressif\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuger Bang\n\n\nCollectif rock breton\n\n\n\n\n\n\n\n\n\n\n\n\n\nPompei\n\n\nPink Floyd & spatialisation sonore\n\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt2/index.html",
    "href": "posts/reseau-neuronne-deconvolution-pt2/index.html",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "",
    "text": "Image générée par IA\nDans l’article précédent, nous avions discuté d’un ensemble de problématiques entourant la création de modèles pour les réseaux de neurones dans le but de simuler des amplificateurs de guitare, ainsi que proposé une piste d’amélioration. Nous la résumerons de la façon suivante :\nVoyons maintenant la mise en pratique."
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt2/index.html#liste-des-courses",
    "href": "posts/reseau-neuronne-deconvolution-pt2/index.html#liste-des-courses",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "Liste des courses",
    "text": "Liste des courses\nL’amplificateur que nous souhaitons modéliser est l’amplificateur de puissance d’un Laney LionHeart L20T-410. Le microphone utilisé est un Behringer ECM8000. L’amplificateur utilisé pour réaliser la réponse impulsionnelle est un Drawmer CPA-50.\nPour assurer la simulation d’amplificateur, la solution choisie est le logiciel « AIDA-X ». Plusieurs raisons expliquent ce choix : AIDA-X est une solution open source. Elle offre une extension multi-plateforme et est accessible via la pédale MOD Dwarf. Elle repose sur RTNeural, un framework open source créé par Jatin Chowdhury.\nLe protocole de création de modèles pour AIDA-X est détaillé dans leur Google Colab. Le principe est relativement simple. On suit les étapes décrites dans le notebook, on récupère le fichier audio à lire au travers du périphérique à modéliser, on enregistre le résultat, puis on envoie les deux fichiers sur le notebook pour réaliser l’entraînement du réseau de neurones."
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt2/index.html#mesure-de-la-réponse-impulsionnelle",
    "href": "posts/reseau-neuronne-deconvolution-pt2/index.html#mesure-de-la-réponse-impulsionnelle",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "Mesure de la réponse impulsionnelle",
    "text": "Mesure de la réponse impulsionnelle\nLa réponse impulsionnelle du haut-parleur est réalisée grâce à REAPER. En effet, le plug-in ReaVerb permet de réaliser une déconvolution si le signal utilisé pour la mesure est un “sweep” logarithmique1. Pour plus d’information sur la procédure à suivre, voilà un lien vers un excellent article de Sound on Sound sur le sujet.\nLe signal sort du convertisseur vers un boîtier de réamping2 pour ensuite attaquer l’entrée de l’amplificateur Dawmer. Le haut-parleur du Laney est directement connecté sur ce dernier.\nUne fois tout cela réalisé, on se retrouve avec cette réponse impulsionnelle."
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt2/index.html#enregistrement-des-empreintes",
    "href": "posts/reseau-neuronne-deconvolution-pt2/index.html#enregistrement-des-empreintes",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "Enregistrement des empreintes",
    "text": "Enregistrement des empreintes\nL’amplificateur Laney possède un réglage de présence. Ce type de réglage contrôle en général un filtre passe-bas dans une boucle de rétroaction partant de la sortie de transformateur vers l’entrée de l’amplificateur de puissance.\nIl a donc été décidé de créer onze empreintes, une pour chacune des valeurs numériques indiquées par le potentiomètre de présence."
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt2/index.html#problématique-de-la-déconvolution-des-empreintes",
    "href": "posts/reseau-neuronne-deconvolution-pt2/index.html#problématique-de-la-déconvolution-des-empreintes",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "Problématique de la déconvolution des empreintes",
    "text": "Problématique de la déconvolution des empreintes\nNous voici donc dans le dur du sujet. Reprenons quelques bases de traitement du signal. Lorsque l’on étudie un système linéaire et invariant temporellement3, on sait que le signal d’entrée et le signal de sortie sont liés à la réponse impulsionnelle du système par l’opération de convolution.\n\\[\ny(t) = x(t) * h(t)\n\\]\nOù \\(x\\) est notre signal d’entré, \\(y\\) notre signal de sortie, et \\(h\\) la réponse impulsionnelle du système.\nNous savons qu’une des propriétés très intéressantes de la transformée de Fourier est de transformer une convolution temporelle en multiplication fréquentielle.\n\\[\nY(f) = X(f) \\times H(f)\n\\]\nOù \\(Y\\), \\(X\\) et \\(H\\) sont les transformée de Fourier respective de \\(y\\), \\(x\\) et \\(h\\).\n\n\n\n\n\n\nImportant\n\n\n\nN’oublions pas, \\(Y(f)\\), \\(X(f)\\) et \\(H(f)\\) sont des nombres complexes4.\n\n\nDès lors, si nous connaissons le signal d’entrée, le signal de sortie et que nous cherchons la réponse impulsionnelle, on trouve facilement que :\n\\[\nH(f) = \\frac{Y(f)}{X(f)}\n\\]\nSeulement, l’opération de division est problématique, puisque, si, pour certaines valeurs de \\(f\\), \\(X(f)\\) vaut zéro, \\(H(f)\\) tendra vers l’infini. Cela se traduira par l’apparition de “sifflantes” dans le signal audio déconvolué.\nUne solution classique au problème consiste d’abord à transformer notre expression précédente afin que le dénominateur de la fonction devienne un réel, puis à y ajouter une erreur pour limiter l’influence des valeurs de \\(X(f)\\) trop proches de zéro.\nOn commence donc par multiplier le dénominateur et le numérateur de notre expression de \\(H(f)\\) par le complexe conjugué de \\(X(f)\\), que nous écrirons \\(X^*(f)\\). On trouve donc :\n\\[\nH(f) = \\frac{Y(f).X^*(f)}{X^2(f)}\n\\]\nOn définit maintenant une erreur, soit constante \\(\\epsilon\\), soit variable en fonction de la fréquence \\(\\epsilon(f)\\). Il en découle alors :\n\\[\nH(f) = \\frac{Y(f).X^*(f)}{X^2(f)+\\epsilon^2(f)}\n\\]\nIl n’existe pas, à ma connaissance, de méthode classique pour déterminer \\(\\epsilon\\). Il est d’usage d’ajouter l’erreur la plus faible possible, afin de limiter l’approximation de l’opération de déconvolution. Dans la même logique, chercher une erreur variable en fonction de la fréquence est en général la meilleure approche.\n\n\n\n\n\n\nAstuce\n\n\n\nLa proposition d’une méthode pour approcher une valeur d’\\(\\epsilon\\) fera peut-être l’objet d’un article. Un jour.\n\n\nOn appelle cette méthode de déconvolution la déconvolution de Weiner."
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt2/index.html#implémentation-de-la-déconvolution",
    "href": "posts/reseau-neuronne-deconvolution-pt2/index.html#implémentation-de-la-déconvolution",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "Implémentation de la déconvolution",
    "text": "Implémentation de la déconvolution\nÀ ma connaissance, il n’existe pas d’outil de déconvolution gratuit n’imposant pas de contrainte sur le signal utilisé pour la mesure. Le plus simple fut donc d’implémenter l’algorithme de déconvolution en Python, en utilisant les librairies Numpy et SciPy.\nLe choix a été fait d’implémenter la déconvolution comme la convolution par la réponse impulsionnelle de l’inverse du spectre du signal d’entrée. Le formalisme mathématique peut ici nous éclairer. Nous avons écrit plus haut :\n\\[\nH(f) = \\frac{Y(f)}{X(f)}\n\\]\nNous pouvons tout aussi bien écrire :\n\\[\nH(f) = Y(f) \\times \\frac{1}{X(f)}\n\\]\nSoit, par transformée de Fourier inverse : \\[\nh(t) = y(t) * x_{inv}(t)\n\\]\nOù \\(TF(x_{inv}(t)) = \\frac{1}{X(f)}\\)\nRappelons-nous tout de même que nous souhaitons limiter l’apparition de sifflante par l’ajout d’une erreur. On pause alors la relation suivante :\n\\[\nTF(x_{inv}(t)) = \\frac{X^*(f)}{X^2(f)+\\epsilon^2(f)}\n\\]\nVoici une proposition d’implémentation en Python:\ndef invert_filter(impulse: np.ndarray, epsilon: np.ndarray = 0):\n    Impulse = np.fft.fft(impulse)\n    Kernel = np.conj(Impulse) / (Impulse*np.conj(Impulse)+np.power(epsilon,2))\n    return np.real(np.fft.ifft(Kernel))\nCette implémentation présuppose que le paramètre epsilon de la fonction est soit un nombre, soit une liste de même taille que le paramètre impulse. Le code suivant propose un exemple de l’utilisation de cette fonction :\nimport numpy as np\nfrom scipy import io, signal\n\n# Fonction de génération de \"l'inverse\" de la réponse impulsionnelle\ndef invert_filter(impulse: np.ndarray, epsilon: np.ndarray = 0):\n    Impulse = np.fft.fft(impulse)\n    Kernel = np.conj(Impulse) / (Impulse*np.conj(Impulse)+np.power(epsilon,2))\n    return np.real(np.fft.ifft(Kernel))\n\n# Conversion décibel vers linéaire\ndef db2a(x):\n    return np.power(10,x/20)\n\n# Définition de la fréquence d'échantillonnage de travail\nfs = 48000\n\n# On charge l'IR et l'empreinte\nimpulse_sr, impulse = io.wavfile.read('impulse_response.wav')\nmodel_sr, model = io.wavfile.read('model.wav')\n\n# On définie le niveau de bruit que l'on va rajouter pour la déconvolution. Ici, l'erreur est donc constante.\nnoise_floor = -100 # dB\n\n# la variable kernel stocke \"l'inverse\" de notre réponse impulsionnelle\nkernel = invert_filter(impulse,db2a(noise_floor))\n\n# La fonction lfilter permet de réaliser l'opération de convolution.\noutput = signal.lfilter(kernel,a=1,x=model)\n\n# Cette normalisation est recommandée par AIDA-X\n# https://mod.audio/modeling-amps-and-pedals-for-the-aida-x-plugin-best-practices/\noutput /= (np.max(output)*db2a(6))\n\n# On écrit la variable output dans un fichier\nio.wavfile.write('model_deconvolved.wav',fs,output)"
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt2/index.html#résultats",
    "href": "posts/reseau-neuronne-deconvolution-pt2/index.html#résultats",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "Résultats",
    "text": "Résultats\nUne fois le script exécuté, on obtient notre fichier cible pour le réseau de neurones, où l’empreinte sonore du haut-parleur a été retirée.\nEn guise de comparaison, voici le même signal audio, avant et après déconvolution :\n\n\n\n\nDans le prochain article, nous regarderons comment implémenter ce modèle sur une carte Bela, puis nous prendrons le temps d’écouter le résultat."
  },
  {
    "objectID": "posts/reseau-neuronne-deconvolution-pt2/index.html#footnotes",
    "href": "posts/reseau-neuronne-deconvolution-pt2/index.html#footnotes",
    "title": "Réseau de neurones et déconvolution - Application à la simulation d’un amplificateur guitare",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nUn sweep est un signal constitué d’un son pur, mais dont la fréquence évolue dans le temps. L’objectif est de couvrir toutes les gammes de fréquences que l’on souhaite examiner. Dans le domaine de la mesure du matériel audio, il est recommandé d’utiliser un balayage logarithmique, où la fréquence augmente ou diminue progressivement selon un schéma logarithmique. Cette approche est avantageuse, car notre sensibilité aux différentes fréquences suit une progression logarithmique.↩︎\nUn boîtier de réamping adapte le signal de niveau ligne pour une entrée d’amplificateur pour guitare.↩︎\nVoir wikipedia.↩︎\nVoir wikipedia↩︎"
  },
  {
    "objectID": "training/pds-mix/index.html",
    "href": "training/pds-mix/index.html",
    "title": "Techniques de prises de son & de mixage",
    "section": "",
    "text": "Cette formation, dispensée par le centre de formation Transversal Studio à Vannes, est une opportunité pour les passionnés de musique et d’audio d’apprendre les techniques de production sonore en studio. Au cours de cette formation complète, les stagiaires découvriront l’ensemble de la chaîne audio, des nuances de l’acoustique à l’utilisation de microphones et d’équipements de pointe. Ils apprendront à capturer le son, en maîtrisant les subtilités du placement de microphones, des techniques stéréophoniques et de la gestion des réseaux casques.\nUne fois de l’autre côté de la vitre du studio, les stagiaires seront prêts à mettre en pratique leurs compétences nouvellement acquises. Ils sauront comment préparer une session, choisir les formats d’enregistrement et communiquer efficacement avec les musiciens. Ils perfectionneront également leurs compétences en mixage, en réalisant des balances et en ajoutant des effets audio pour créer des productions musicales de qualité professionnelle."
  },
  {
    "objectID": "training/spat-revolution/index.html",
    "href": "training/spat-revolution/index.html",
    "title": "SPAT Revolution",
    "section": "",
    "text": "Cette formation immersive sur le logiciel SPAT Revolution de FLUX:: est conçue pour les professionnels de l’audio souhaitant maîtriser la spatialisation sonore et créer des expériences audio immersives. Au début de la formation, les stagiaires découvriront les bases de SPAT Revolution, y compris l’installation et l’activation. Ensuite, ils plongeront dans les détails, explorant les différentes techniques de spatialisation, les différentes lois de panoramique, ou encore les différents paramètres de mixage et de perception sonores pour créer des scénarios sonores fascinants.\nAu cours de la formation, les stagiaires apprendront à automatiser des objets sonores, à configurer des systèmes de haut-parleurs, et à contrôler SPAT Revolution, via d’OSC, à l’aide d’iPad, et d’autres dispositifs. Ils développeront également des compétences essentielles pour la création de contenus immersifs, en travaillant sur des travaux pratiques concrets.\nCette formation ouvrira donc à ses stagiaires les portes de la spatialisation sonore et du logiciel SPAT Revolution."
  },
  {
    "objectID": "training/reaper/index.html",
    "href": "training/reaper/index.html",
    "title": "Production sonore avec REAPER",
    "section": "",
    "text": "Cette formation approfondie de REAPER, d’une durée de cinq jours, vise à familiariser les stagiaires avec ce logiciel puissant dédié à la production audio et à la composition musicale. Tout au long de cette formation, les stagiaires seront guidés à travers un apprentissage progressif pour qu’ils puissent maîtriser toutes les facettes de REAPER.\nDès le début, les participants seront plongés dans l’univers de REAPER, en commençant par l’installation, la configuration et la découverte de son interface. Ils apprendront à personnaliser REAPER pour qu’il corresponde parfaitement à leurs besoins spécifiques. Ensuite, ils plongeront dans l’enregistrement audio, en découvrant les techniques de gestion des prises, le routage audio et les compétences essentielles pour le montage audio. Ils auront également l’occasion d’acquérir des compétences avancées en matière d’édition audio, de manipulation de l’audio et de création de marqueurs.\nAu cours de la formation, les stagiaires exploreront également les aspects du mixage dans REAPER, en découvrant la bibliothèque d’effets, les automations, les groupes de pistes et bien d’autres fonctionnalités essentielles pour donner vie à leurs projets musicaux. Ils découvriront comment personnaliser encore davantage REAPER en configurant des raccourcis, des macros et en explorant les extensions et les scripts pour étendre leurs compétences de production audio. Cette formation permettra aux stagiaires de devenir des utilisateurs expérimentés de REAPER, capables de tirer pleinement parti de ce logiciel dans leurs projets musicaux et sonores."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projets",
    "section": "",
    "text": "Guide pratique des techniques du son\n\n\n\n\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReaVolution\n\n\n\n\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "training.html",
    "href": "training.html",
    "title": "Cours & Formations",
    "section": "",
    "text": "Techniques de prises de son & de mixage\n\n\n\n\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInitiation à la programmation\n\n\n\n\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSPAT Revolution\n\n\n\n\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInformatique audio\n\n\n\n\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduction sonore avec REAPER\n\n\n\n\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInitiation à la 3D sonore\n\n\n\n\n\n\nJean-Loup Pecquais\n\n\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html",
    "href": "posts/ambisonic-reaper-1/index.html",
    "title": "Mixage Ambisonique dans REAPER - Introduction",
    "section": "",
    "text": "image générée par IA"
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#structure-de-mixage",
    "href": "posts/ambisonic-reaper-1/index.html#structure-de-mixage",
    "title": "Une Alternative au Dolby Atmos",
    "section": "Structure de mixage",
    "text": "Structure de mixage\nExaminons d’abord comment structurer le routage d’une session dans le contexte d’un mixage ambisonique. Dans le cadre d’une prise de son reposant sur de la multi-microphonie, la première question qui vient est donc : faut-il encoder en ambisonie chaque microphone ? D’expérience, il semble que non. Voir, il serait préférable d’encoder les différents instruments. Quelle est la nuance entre les deux ?\nUne basse, par exemple, est généralement enregistrée en monophonie, avec quelques microphones et une DI. Il est alors judicieux de sommer d’abord l’ensemble de ces signaux pour former un bus dédié à l’instrument de basse. On peut ensuite encoder cet instrument.\nPour les instruments enregistrés grâce à un couple stéréophonique et complété par des appoints, on aura alors tendance à appliquer la même méthodologie : router l’ensemble des microphones dans un bus (ici stéréophonique) et encoder le signal stéréo en ambisonie.\nDans les rares cas où un instrument est enregistré à l’aide d’un microphone ambisonique et complété par des appoints, on pourrait alors, dans ce cas, encoder directement les appoints en ambisonie avant de former le bus instrument. Une prise de son ambisonique est souvent intéressante pour capturer l’acoustique du lieu. Dans ce cas, elle peut être considérée comme étant séparée du bus instrument.\nConcernant l’ajout de traitement et d’effets, il est alors vivement conseillé de réaliser un maximum de traitement avant l’encodage ambisonique. En effet, traiter 16 canaux est forcément beaucoup plus coûteux que d’en traiter deux (on pourrait se laisser dire huit fois plus coûteux.). De plus les plug-ins multicanaux sont rares, mais nous réaborderons ce point plus loin.\nConcrètement, on placera alors la majorité, voire l’intégralité des traitements avant l’encodeur ambisonique dans la chaîne d’effet de la piste. D’un point de vue optimisation des ressources, il semble que certaines heuristiques d’optimisation dans REAPER fonctionnent moins bien sur des pistes multicanaux, même si les plugins eux-mêmes n’ont que deux canaux d’entrée/sortie. Pour résoudre ce problème, il convient alors de placer les effets pré-encodage dans un conteneur qui, lui, n’aura que deux canaux."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#gestion-du-side-chain",
    "href": "posts/ambisonic-reaper-1/index.html#gestion-du-side-chain",
    "title": "Une Alternative au Dolby Atmos",
    "section": "Gestion du side-chain",
    "text": "Gestion du side-chain\nLe side-chain est une technique de compression permettant de compresser un signal à partir de l’enveloppe d’un autre signal. Le cas classique, popularisé par les musiques électroniques, est la compression de la basse par l’enveloppe du kick.\nOr, nos pistes ayant maintenant 16 canaux, il semble alors compliqué de pouvoir alimenter le circuit de détection d’un compresseur mono ou stéréo à partir d’un tel signal. Heureusement, nous avons une solution très simple à ce problème.\nLe premier canal de n’importe quel signal ambisonique, appelé généralement canal « W », correspond à une directivité omnidirectionnelle. En d’autres termes, ce canal représente le signal de notre instrument, indépendamment de la spatialisation que nous avons pu lui faire subir.\nPour réaliser une compression en side-chain, on pourra alors envoyer le canal W de notre piste de kick (donc le premier canal) dans le canal 17 de la piste de basse que l’on souhaite compresser.\nLa gestion des départs auxiliaires et des effets en parallèle\nAbordons maintenant la question des départs auxiliaires. Il convient de distinguer deux cas pratiques :\n\nAlimenter un effet mono ou stéréo, qui sera par la suite encodé en ambisonie, à partir d’un signal déjà encodé\nAlimenter un effet ambisonique à partir d’une piste ambisonique\n\nAvant de rentrer dans le détail, nous allons devoir détailler une astuce de mixage, également applicable en mixage stéréophonique.\nPlutôt que de directement router une piste vers un effet, type réverbération, on pourrait alors utiliser une piste intermédiaire, nous permettant de ce fait d’accéder à du traitement par envois dans un effet. En pratique, on commence par router la piste d’instrument dans une nouvelle piste, puis on place cette dernière dans une piste dossier. Sur ce dossier est instanciée la réverbération que l’on souhaite utiliser. Précisons par ailleurs qu’une piste ne consomme presque aucune ressource dans REAPER et que de telles manipulations de routage peuvent être largement simplifiées et automatisées par l’usage de scripts.\nRevenons au cas d’un mixage ambisonique.\nDans le premier cas, nous allons appliquer l’astuce déjà abordée précédemment. On route le canal W de notre flux ambisonique vers une nouvelle piste. Cette piste est alors placée dans un dossier qui contient l’effet mono ou stéréo. On encode ensuite cet effet en ambisonie.\nDans le second cas, nous allons alors envoyer les 16 canaux ambisoniques vers la nouvelle piste qui sera elle aussi placée dans un dossier qui contient l’effet. Dès lors, comme nous avons une piste intermédiaire, nous pouvons utiliser un effet ambisonique pour tourner la scène ambisonique de notre instrument, seulement pour l’entrée de l’effet. On peut alors imaginer avoir un instrument venant de la gauche et avoir sa réverbération provenant de la droite."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#transformer-une-réverbération-stéréo-en-réverbération-ambisonique",
    "href": "posts/ambisonic-reaper-1/index.html#transformer-une-réverbération-stéréo-en-réverbération-ambisonique",
    "title": "Une Alternative au Dolby Atmos",
    "section": "Transformer une réverbération stéréo en réverbération ambisonique",
    "text": "Transformer une réverbération stéréo en réverbération ambisonique\nLes réverbérations ambisoniques sont rares. Voici alors une petite astuce permettant de recycler des réverbérations stéréo. Bien sûr, il n’est pas question ici de réalisme acoustique, mais simplement de retrouver une sensation d’enveloppement. Voici l’ensemble de la chaîne de traitement de la piste de réverbération :\n\nOn commence par tronquer l’ordre ambisonique pour obtenir un signal du premier ordre.\nOn décode ce signal ambisonique sur un arrangement t-design 4\nOn place une instance de réverbération sur les canaux 1-2 et une autre sur les canaux 3-4\nOn applique un algorithme de décorrélation sur les canaux 3-4 (ou 1-2, peu importe).\nOn réencode le t-design 4 en ambisonie du premier ordre\nOn up-mix l’ambisonie d’ordre 1 vers l’ordre 3.\n\nExpliquons un peu plus en détail.\nTout d’abord, le choix du premier ordre est vivement conseillé pour simplifier le réglage des réverbérations. En effet, il faudra régler deux instances, et pas une ! Mieux vaut alors ne pas multiplier le nombre d’instances pour que le travail ne devienne pas trop fastidieux.\nL’arrangement t-design 4 contient quatre haut-parleurs, placés de façon homogène et uniforme. Il s’agit donc d’un cas idéal pour l’ambisonie.\nL’étape de décorrélation est nécessaire pour garantir une différence suffisante entre les canaux pour que l’on n’ait pas l’impression d’entendre deux fois la même réverbération, et donc perdre totalement la sensation d’espace.\nAprès le réencodage, une étape d’up-mixing permet de rejoindre notre ordre ambisonique initial.\nCe travail étant laborieux, on s’empressera de créer une « FX chain » dans REAPER pour ne pas avoir à répéter ce processus."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#égalisation-de-bus-ambisonique",
    "href": "posts/ambisonic-reaper-1/index.html#égalisation-de-bus-ambisonique",
    "title": "Une Alternative au Dolby Atmos",
    "section": "Égalisation de bus ambisonique",
    "text": "Égalisation de bus ambisonique\nL’égalisation de bus ambisonique ne pose pas de problème particulier. Il convient simplement d’appliquer la même correction à l’ensemble des canaux. Il faudra alors un outil supportant au moins 16 canaux pour de l’ordre trois."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#compression-et-traitement-non-linéaire-de-bus-ambisonique",
    "href": "posts/ambisonic-reaper-1/index.html#compression-et-traitement-non-linéaire-de-bus-ambisonique",
    "title": "Une Alternative au Dolby Atmos",
    "section": "Compression et traitement non linéaire de bus ambisonique",
    "text": "Compression et traitement non linéaire de bus ambisonique\nLa question de la compression d’un bus ambisonique est moins simple. La difficulté principale est que la présence d’énergie dans un canal ambisonique n’implique pas une relation directe avec sa position dans l’espace. Dès lors, la compression différenciée des canaux est contre indiquée pour éviter la dégradation de la spatialisation.\nOn trouve alors deux solutions. La première, et la plus simple, est de compresser l’ensemble des canaux du flux ambisonique en ne détectant l’enveloppe que sur le premier canal, dit W.\nL’autre solution consiste à décoder le signal ambisonique sur un t-design adéquat à l’ordre, puis de compresser le signal décodé, et, enfin, de réencoder le signal compressé.\nCertains compresseurs permettent aussi une compression par masquage spatial. On ne compresse ainsi que certaines zones de l’espace. Le compresseur de la suite IEM en est un bon exemple.\nPour les autres types de traitement non linéaire (saturation, limiteur, etc), on appliquera le même raisonnement que pour la compression."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#quels-effets-pour-le-traitement-de-signaux-ambisoniques",
    "href": "posts/ambisonic-reaper-1/index.html#quels-effets-pour-le-traitement-de-signaux-ambisoniques",
    "title": "Mixage Ambisonique dans REAPER",
    "section": "Quels effets pour le traitement de signaux ambisoniques",
    "text": "Quels effets pour le traitement de signaux ambisoniques\nGlobalement, peu de constructeurs offrent leurs plug-ins en version multicanal. Particulièrement, l’ambisonie reste un marché de niche. Voici une liste non exhaustive de constructeurs particulièrement tournés vers cette technologie :\n\nIEM (open source & gratuit)\nSPARTA (open source & gratuit)\nFLUX::\nSound Particule\nNoise Maker\nBlue Ripple (principalement payant, onéreux et sans version de démo !)\nAudio Brewers (payant et sans version de démo !)\n\nCertains constructeurs prennent le parti de supporter un grand nombre de canaux, sans particulièrement se préoccuper de leur usage :\n\nREAPER (les principaux plug-ins supportent jusqu’à 128 canaux)\nMelda Production (64 canaux)\n\nBien que d’apparence disgracieuse, les plug-ins natifs de REAPER sont d’excellentes qualités. L’ensemble des fonctionnalités est généralement exhaustif sans être trop compliqué, et la qualité sonore est remarquable. Dans le cas du compresseur, il est possible de compresser l’ensemble des canaux en ne détectant l’enveloppe que sur le premier canal. Cette méthode est très utile en ambisonie.\nLes plugins de Melda Production peuvent également être une solution intéressante. Ils sont, cependant, souvent trop chargés en fonctionnalités de second ou troisième plan, et passent parfois à côté de choses élémentaires. L’UI est fastidieuse à naviguer et certains algorithmes sont franchement décevants (MAutoAlign). Mais pour autant, ils offrent un large panel d’outils dont la plupart s’adaptent bien au travail ambisonique, jusqu’au septième ordre. Particulièrement, leur MTurboReverb est une réussite !\nAussi important à mentionner, Jatin Chowdurry développe une excellente simulation à bande nommée ChowTapeModel et qui supporte un nombre arbitraire de canaux ! À tester urgemment.\nEnfin, la plupart des constructeurs offrant du multicanal le font dans le contexte de l’écosystème Dolby Atmos. Aujourd’hui, il n’est pas si rare de trouver des plug-ins gérant du 9.1.6, donc potentiellement les 16 canaux d’un ambisonie du troisième ordre (Pro Q 4 de Fabfilter, par exemple). Pour les plug-ins plafonnant à du 7.1.4, on pourra toujours passer par une étape de décodage et de réencodage ambisonique. Cette approche est parfaitement justifiable pour des effets, comme les délais et la réverbération. Pour un traitement sériel, la dégradation de l’image spatiale risque de ne pas en valoir la chandelle."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#le-monitoring",
    "href": "posts/ambisonic-reaper-1/index.html#le-monitoring",
    "title": "Une Alternative au Dolby Atmos",
    "section": "Le monitoring",
    "text": "Le monitoring"
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#conclusions",
    "href": "posts/ambisonic-reaper-1/index.html#conclusions",
    "title": "Mixage Ambisonique dans REAPER - Introduction",
    "section": "Conclusions",
    "text": "Conclusions\nBien que le Dolby Atmos soit souvent présenté comme une révolution dans le domaine de la spatialisation sonore, il présente plusieurs défauts notables qui remettent en question son adoption massive. Les limitations techniques, telles que la dépendance à des systèmes de diffusion spécifiques et hétérogènes, la variation de la perception de la largeur de la source, et l’absence de solutions satisfaisantes pour le traitement de groupes d’objets, sont autant de freins à son utilisation. De plus, la complexité accrue du mastering et la qualité discutable du rendu binaural ajoutent à ces préoccupations.\nEn revanche, l’ambisonie, une technologie plus ancienne, mais tout aussi prometteuse, offre des avantages similaires sans ces inconvénients. Grâce à des techniques de matriçage et à des décodeurs améliorés, l’ambisonie permet une flexibilité accrue et une meilleure interopérabilité des outils. Les suites de plug-ins comme IEM et SPARTA, qui sont distribuées gratuitement et open source, facilitent l’adoption de cette technologie.\nPour les ingénieurs du son souhaitant explorer la spatialisation sonore, l’ambisonie représente une alternative solide et éprouvée. En utilisant des logiciels comme REAPER, qui supportent un grand nombre de canaux, il est possible de réaliser des mixages ambisoniques de haute qualité tout en conservant les habitudes et techniques de mixage stéréophonique.\nAinsi, plutôt que de se laisser séduire par les promesses marketing du Dolby Atmos, il serait judicieux de se tourner vers l’ambisonie, une technologie qui a fait ses preuves et qui continue d’évoluer grâce aux contributions de la communauté scientifique et des passionnés du son."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#introduction",
    "href": "posts/ambisonic-reaper-1/index.html#introduction",
    "title": "Mixage Ambisonique dans REAPER - Introduction",
    "section": "Introduction",
    "text": "Introduction\n\nLa “révolution” de l’Atmos ?\nÀ l’heure où j’écris cet article, en début 2025, la spatialisation sonore dans la musique enregistrée prend le visage du Dolby Atmos. Trente ans plus tôt, c’était le 5.1 surround, puis le 7.1 et maintenant, la firme américaine nous propose un format de mixage orienté objet, permettant ainsi, théoriquement, de s’affranchir de la connaissance du système de diffusion lors de la phase de mixage.\nNe faisons pas durer le suspense plus longtemps, je fais partie des personnes tout à fait dubitatives devant l’engouement provoqué par cette technologie. En effet, je crois ses défauts assez nombreux. Prenons le temps d’en énumérer quelques-uns :\n\nUn mixage réalisé en Dolby Atmos ne peut être rendu, à ce jour, que sur certains systèmes de diffusion particuliers (5.1.2,7.1.4,9.1.6,etc.), tous ses systèmes ayant le mauvais goût d’être hétérogènes dans la répartition des haut-parleurs dans l’espace.\nLa loi de panoramique adopté par le Dolby Atmos emprunte beaucoup au Vector Based Amplitude Panning (ou VBAP). Bien que le VBAP possède un certain nombre de qualités (économe en ressources et relativement robuste face à des systèmes de diffusion non homogène), il possède malheureusement un inconvénient : il génère une variation de la perception de la largeur de la source en fonction de sa position. Cela s’entend particulièrement sur des mouvements.\nIl n’existe, à ce jour, pas de solution réellement satisfaisante pour le traitement des groupes d’objets. Quid de la compression de bus, de la compression parallèle et autres traitements aujourd’hui synonymes de certaines esthétiques de production ? Dolby, et les acteurs de l’industrie du son « immersif » répondent en général que l’amélioration des outils de spatialisation améliore également le démasquage (par la multiplication du nombre d’enceintes). Il s’agit d’un argument de techniciens, ne faisant pas la part des choses entre des traitements sonores de nécessité technique et ceux de nécessité esthétique.\nComme il n’existe plus de bus master en Atmos, la notion de mastering devient elle aussi bien compliquée. De plus, les résultats peuvent varier considérablement en fonction du format de restitution (haut-parleurs ou casque avec synthèse binaurale). Ici encore, aucune solution correcte n’est proposée, Dolby allant même jusqu’à proclamer que l’Atmos rend le mastering inutile.\nLa qualité sonore du rendu binaural des mixages Atmos est tout à fait discutable.\nLe prix de la chaîne de production Atmos est souvent prohibitif.\n\nMais tous ces défauts ne seraient rien sans la volonté de Dolby de faire passer sa technologie pour une révolution. Cette posture est particulièrement agaçante, car elle semble nier près de cent années de recherches sur le sujet. Car oui, la question de la spatialisation sonore de synthèse remonte presque aussi loin que l’invention de l’enregistrement sonore.\n\n\nL’alternative de l’ambisonie\nIl existe pourtant une technologie, dont la naissance remonte aux années soixante-dix, et qui proposait déjà des avantages similaires à l’Atmos : l’ambisonie. Mis au point par un génial ingénieur anglais, Michael Gerzon1, l’ambisonie permet, grâce à une technique de matriçage, de réaliser un mixage sans se soucier du système de diffusion (casque ou haut-parleurs, peu importe leurs nombres, etc.).\n\n\n\nMichael Gerzon - Prise de son ambisonique avec microphones discrets\n\n\nGerzon réalisa de nombreux enregistrements ambisoniques et fut aussi le concepteur des microphones Soundfield, marque aujourd’hui possédée par Rhodes. De santé fragile, il décéda dans les années quatre-vingt-dix.\nDepuis, de nombreuses recherches ont eu à cœur d’améliorer le procédé ambisonique. D’abord, par l’introduction de l’ambisonie d’ordre plus élevé (Higher Order Ambisonic - HOA), permettant ainsi un meilleur adressage des systèmes comportant beaucoup d’enceintes. Puis par l’élaboration de décodeurs optimisant le rendu ambisonique sur des systèmes non homogènes, comme le AllRound Ambisonic Decoder (AllRAD) et l’Energy Preserving Ambisonic Decoder (EPAD).\nIl existe aujourd’hui deux suites de plug-ins majeures permettant la création de mixages ambisonique:\n\nLa suite IEM\nLa suite SPARTA\n\n\n\n\n\n\n\n\n\n\nEnergyVisualizer de la suite IEM\n\n\n\n\n\n\n\n\n\nPlugins de la suite SPARTA\n\n\n\n\n\nToutes les deux sont distribuées gratuitement et sont open source. Cependant, un mixage ambisonique, surtout quand il utilise les ordres plus élevés, devient rapidement gourmand en nombre de canaux par piste. Un mixage réalisé à l’ordre 3 demande déjà seize canaux par pistes encodées. Il convient donc de trouver un logiciel de mixage permettant cette flexibilité.\nREAPER est une station de travail audio numérique développé par l’entreprise Cockos. Édité depuis 2005, ce logiciel a conquis une large communauté grâce à son grand nombre de fonctionnalités, ses grandes possibilités de personnalisation et un tarif terriblement concurrentiel. Dans notre cas d’usage, il est bon de dire que chaque piste, dans REAPER, supporte jusqu’à 128 canaux. Nous pouvons donc employer l’ambisonie d’ordre 10 (121 canaux) 2.\nCet article sert d’introduction à une série qui aura à cœur d’expliquer les éléments théoriques et pratiques du mixage ambisonique avec une attention particulière à proposer une méthode de travail simple, claire et qui ne remet pas en cause près de cent ans de pratiques techniques et surtout esthétiques dans nos métiers.\nLe prochain article traitera de la théorie entourant la pratique de l’ambisonique."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#conseils-de-mixage",
    "href": "posts/ambisonic-reaper-1/index.html#conseils-de-mixage",
    "title": "Mixage Ambisonique dans REAPER - Introduction",
    "section": "Conseils de mixage",
    "text": "Conseils de mixage\n\nStructurer sa console\n\nExaminons d’abord comment structurer le routage d’une session dans le contexte d’un mixage ambisonique. Dans le cadre d’une prise de son reposant sur de la multi-microphonie, la première question qui vient est donc : faut-il encoder en ambisonie chaque microphone ? D’expérience, il semble que non. Voir, il serait préférable d’encoder les différents instruments. Quelle est la nuance entre les deux ?\nUne basse, par exemple, est généralement enregistrée en monophonie, avec quelques microphones et une DI. Il est alors judicieux de sommer d’abord l’ensemble de ces signaux pour former un bus dédié à l’instrument de basse. On peut ensuite encoder cet instrument.\nPour les instruments enregistrés grâce à un couple stéréophonique et complété par des appoints, on aura alors tendance à appliquer la même méthodologie : router l’ensemble des microphones dans un bus (ici stéréophonique) et encoder le signal stéréo en ambisonie.\nDans les rares cas où un instrument est enregistré à l’aide d’un microphone ambisonique et complété par des appoints, on pourrait alors, dans ce cas, encoder directement les appoints en ambisonie avant de former le bus instrument. Une prise de son ambisonique est souvent intéressante pour capturer l’acoustique du lieu. Dans ce cas, elle peut être considérée comme étant séparée du bus instrument.\nConcernant l’ajout de traitement et d’effets, il est alors vivement conseillé de réaliser un maximum de traitement avant l’encodage ambisonique. En effet, traiter 16 canaux est forcément beaucoup plus coûteux que d’en traiter deux (on pourrait se laisser dire huit fois plus coûteux.). De plus les plug-ins multicanaux sont rares, mais nous réaborderons ce point plus loin.\nConcrètement, on placera alors la majorité, voire l’intégralité des traitements avant l’encodeur ambisonique dans la chaîne d’effet de la piste. Du point de vue de l’optimisation des ressources, il semble que certaines heuristiques d’optimisation dans REAPER fonctionnent moins bien sur des pistes multicanales, même si les plugins eux-mêmes n’ont que deux canaux d’entrée/sortie. Pour résoudre ce problème, il convient alors de placer les effets préencodage dans un conteneur qui, lui, n’aura que deux canaux.\n\n\nGestion des effets\n\nÉgalisation et traitement linéaires et invariants temporellement de bus ambisonique\n\nL’égalisation de bus ambisonique ne pose pas de problème particulier. Il convient simplement d’appliquer la même correction à l’ensemble des canaux. Il faudra alors un outil supportant au moins 16 canaux pour de l’ordre trois. Le même raisonnement s’applique pour tous les traitements linéaires et invariants temporellement.\n\n\nCompression et traitement non linéaire de bus ambisonique\n\nLa question de la compression d’un bus ambisonique est moins simple. La difficulté principale est que la présence d’énergie dans un canal ambisonique n’implique pas une relation directe avec sa position dans l’espace. Dès lors, la compression différenciée des canaux est contre-indiquée pour éviter la dégradation de la spatialisation.\nOn trouve alors deux solutions. La première, et la plus simple sont de compresser l’ensemble des canaux du flux ambisonique en ne détectant l’enveloppe que sur le premier canal, dit W.\nL’autre solution consiste à décoder le signal ambisonique sur un t-design adéquat à l’ordre, puis de compresser le signal décodé, et, enfin, de réencoder le signal compressé.\nCertains compresseurs permettent aussi une compression par masquage spatial. On ne compresse ainsi que certaines zones de l’espace. Le compresseur de la suite IEM en est un bon exemple.\nPour les autres types de traitement non linéaire (saturation, limiteur, etc), on appliquera le même raisonnement que pour la compression.\n\n\nGestion du side-chain\n\nLe side-chain est une technique de compression permettant de compresser un signal à partir de l’enveloppe d’un autre signal. Le cas classique, popularisé par les musiques électroniques, est la compression de la basse par l’enveloppe du kick.\nOr, nos pistes ayant maintenant 16 canaux, il semble alors compliqué de pouvoir alimenter le circuit de détection d’un compresseur mono ou stéréo à partir d’un tel signal. Heureusement, nous avons une solution très simple à ce problème.\nLe premier canal de n’importe quel signal ambisonique, appelé généralement canal « W », correspond à une directivité omnidirectionnelle. En d’autres termes, ce canal représente le signal de notre instrument, indépendamment de la spatialisation que nous avons pu lui faire subir.\nPour réaliser une compression en side-chain, on pourra alors envoyer le canal W de notre piste de kick (donc le premier canal) dans le canal 17 de la piste de basse que l’on souhaite compresser.\n\n\nLa gestion des départs auxiliaires et des effets en parallèle\n\nAbordons maintenant la question des départs auxiliaires. Il convient de distinguer deux cas pratiques :\n\nAlimenter un effet mono ou stéréo, qui sera par la suite encodé en ambisonie, à partir d’un signal déjà encodé\nAlimenter un effet ambisonique à partir d’une piste ambisonique\n\nAvant de rentrer dans le détail, nous allons devoir détailler une astuce de mixage, également applicable en mixage stéréophonique.\nPlutôt que de directement router une piste vers un effet, type réverbération, on pourrait alors utiliser une piste intermédiaire, nous permettant de ce fait d’accéder à du traitement par envois dans un effet. En pratique, on commence par router la piste d’instrument dans une nouvelle piste, puis on place cette dernière dans une piste dossier. Sur ce dossier est instanciée la réverbération que l’on souhaite utiliser. Précisons par ailleurs qu’une piste ne consomme presque aucune ressource dans REAPER et que de telles manipulations de routage peuvent être largement simplifiées et automatisées par l’usage de scripts.\nRevenons au cas d’un mixage ambisonique.\nDans le premier cas, nous allons appliquer l’astuce déjà abordée précédemment. On route le canal W de notre flux ambisonique vers une nouvelle piste. Cette piste est alors placée dans un dossier qui contient l’effet mono ou stéréo. On encode ensuite cet effet en ambisonie.\nDans le second cas, nous allons alors envoyer les 16 canaux ambisoniques vers la nouvelle piste qui sera elle aussi placée dans un dossier qui contient l’effet. Dès lors, comme nous avons une piste intermédiaire, nous pouvons utiliser un effet ambisonique pour tourner la scène ambisonique de notre instrument, seulement pour l’entrée de l’effet. On peut alors imaginer avoir un instrument venant de la gauche et avoir sa réverbération provenant de la droite.\n\n\nRéverbération et synthèse d’espace\nUn outil clé en mixage est la réverbération afin de créer une impression de profondeur dans l’image sonore. Dans le cadre d’un mixage ambisonique, le plus simple est alors d’utiliser des réverbérations ambisoniques. Le problème est que celles-ci sont rares ! On pensera notamment à :\n\nL’IRCAM Verb de FLUX::\nL’AmbiVerb de NoiseMaker\nLa FDN Reverb de IEM\n\nFace à ce nombre limité d’outils, on est alors tenté d’exploiter des effets multicanaux, mais pas forcément ambisoniques.\n\nIntégrer une réverbération multicanal dans un mixage ambisonique\nOn trouve aujourd’hui un grand nombre de réverbérations multicanales, principalement dédiées au Dolby Atmos. Celles-ci supportent en général douze canaux d’entrées (7.1.4), voire seize (9.1.6). Il conviendra de toujours décoder le signal audio ambisonique avant d’attaque une réverbération multicanal. On réencode ensuite le signal de la réverbération.\nSi la réverbération employée propose un nombre de canaux suffisant et d’organisation spatial arbitraire, on préfèrera décodé le signal ambisonique vers des arrangements homogènes et uniformes (t-design par exemple).\n\n\nTransformer une réverbération stéréo en réverbération ambisonique\nLes réverbérations ambisoniques sont rares. Voici alors une petite astuce permettant de recycler des réverbérations stéréo. Bien sûr, il ne s’agit pas ici de réalisme acoustique, mais simplement de retrouver une sensation d’enveloppement. Voici l’ensemble de la chaîne de traitement de la piste de réverbération :\n\nOn commence par tronquer l’ordre ambisonique pour obtenir un signal du premier ordre.\nOn décode ce signal ambisonique sur un arrangement t-design 4\nOn place une instance de réverbération sur les canaux 1-2 et une autre sur les canaux 3-4\nOn applique un algorithme de décorrélation sur les canaux 3-4 (ou 1-2, peu importe).\nOn réencode le t-design 4 en ambisonie du premier ordre\nOn up-mix l’ambisonie d’ordre 1 vers l’ordre 3.\n\nExpliquons un peu plus en détail.\nTout d’abord, le choix du premier ordre est vivement conseillé pour simplifier le réglage des réverbérations. En effet, il faudra régler deux instances, et pas une ! Mieux vaut alors ne pas multiplier le nombre d’instances pour que le travail ne devienne pas trop fastidieux.\nL’arrangement t-design 4 contient quatre haut-parleurs, placés de façon homogène et uniforme. Il s’agit donc d’un cas idéal pour l’ambisonie.\nL’étape de décorrélation est nécessaire pour garantir une différence suffisante entre les canaux pour que l’on n’ait pas l’impression d’entendre deux fois la même réverbération, et donc perdre totalement la sensation d’espace.\nAprès le réencodage, une étape d’up-mixing permet de rejoindre notre ordre ambisonique initial.\n\nCe travail étant laborieux, on s’empressera de créer une « FX chain » dans REAPER pour ne pas avoir à répéter ce processus.\n\n\n\nQuels effets pour le traitement de signaux ambisoniques\nGlobalement, peu de constructeurs offrent leurs plug-ins en version multicanal. Particulièrement, l’ambisonie reste un marché de niche. Voici une liste non exhaustive de constructeurs particulièrement tournés vers cette technologie :\n\nIEM (open source & gratuit)\nSPARTA (open source & gratuit)\nFLUX::\nSound Particule\nNoise Maker\nBlue Ripple (principalement payant, onéreux et sans version de démo !)\nAudio Brewers (payant et sans version de démo !)\n\nCertains constructeurs prennent le parti de supporter un grand nombre de canaux, sans particulièrement se préoccuper de leur usage :\n\nREAPER (les principaux plug-ins supportent jusqu’à 128 canaux)\nMelda Production (64 canaux)\n\nBien que d’apparence disgracieuse, les plug-ins natifs de REAPER sont d’excellentes qualités. L’ensemble des fonctionnalités est généralement exhaustif sans être trop compliqué, et la qualité sonore est remarquable. Dans le cas du compresseur, il est possible de compresser l’ensemble des canaux en ne détectant l’enveloppe que sur le premier canal. Cette méthode est très utile en ambisonie.\nLes plugins de Melda Production peuvent également être une solution intéressante. Ils sont, cependant, souvent trop chargés en fonctionnalités de second ou troisième plan, et passent parfois à côté de choses élémentaires. L’UI est fastidieuse à naviguer et certains algorithmes sont franchement décevants (MAutoAlign). Mais pour autant, ils offrent un large panel d’outils dont la plupart s’adaptent bien au travail ambisonique, jusqu’au septième ordre. Particulièrement, leur MTurboReverb est une réussite !\nAussi important à mentionner, Jatin Chowdurry développe une excellente simulation à bande nommée ChowTapeModel et qui supporte un nombre arbitraire de canaux ! À tester urgemment.\nEnfin, la plupart des constructeurs offrant du multicanal le font dans le contexte de l’écosystème Dolby Atmos. Aujourd’hui, il n’est pas si rare de trouver des plug-ins gérant du 9.1.6, donc potentiellement les 16 canaux d’un ambisonie du troisième ordre (Pro Q 4 de Fabfilter, par exemple). Pour les plug-ins plafonnant à du 7.1.4, on pourra toujours passer par une étape de décodage et de réencodage ambisonique. Cette approche est parfaitement justifiable pour des effets, comme les délais et la réverbération. Pour un traitement sériel, la dégradation de l’image spatiale risque de ne pas en valoir la chandelle.\n\n\n\nLe monitoring\nÀ ce stage, nous ne sommes pas en mesure d’écouter notre mix. Pourquoi ? Un mixage ambisonique doit être décodé vers un arrangement de haut-parleur particulier afin de pouvoir être écouté. Entendons-nous, la question du décodage ambisonique est délicate et mériterais un article à part entière pour commencer à gratter la surface du sujet. Ici, nous nous contenterons de quelques recommandations.\n\nAmbisonie vers stéréophonie\nL’idée peut sembler étrange, pourtant, la stéréophonie reste le format de production dominant en audio. Le but ici n’est pas de retranscrire la sensation de spatialisation sur une paire de haut-parleurs, mais simplement de proposer une réduction robuste et efficace. Pour cela, l’UHJ est une solution intéressante. En effet, ce format ambisonique est un rematriçage de l’ambisonie du premier ordre. On a donc toujours quatre canaux, mais les deux premiers sont écoutables comme une stéréo classique. Encore mieux, il est possible de décoder une quadriphonie à partir de ces deux premiers canaux. On retrouve ici le principe du matriçage quadriphonique 4-2-4. Dolby s’en est d’ailleurs fortement inspiré pour créer son encoder-décodeur “Dobly Stereo” 2\nEn pratique, un convertisseur UHJ est disponible pour REAPER, au format JSFX 3 ici. C’est utilitaire est développé gratuitement par Bruce Wiggins.\n\n\nAmbisonie vers un arrangement quelconque\nPlusieurs outils permettent de décoder vers un arrangement de haut-parleur quelconque, on pense à AllRAD Decoder de la suite IEM et à AmbiDEC de SPARTA. Bien que cette discussion dépasse le cadre de cet article, il faut mentionner que l’utilisation d’un décodage AllRAD ou EPAD est souvent préférable, et ce, particulièrement lorsqu’on décode son signal ambisonique vers un arrangement de haut-parleurs qui n’est pas homogène.\n\n\nAmbisonie vers binaural\nLe monitoring d’une scène ambisonique en binaural est une option particulièrement intéressante, puisque l’on peut, en théorie, s’extraire de la contrainte du système de haut-parleurs. La faiblesse du rendu binaural réside souvent dans une dégradation des timbres. Cela dit, l’ambiBIN de SPARTA est un décodeur particulièrement bluffant en ce sens. Une option à explorer donc."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/index.html#footnotes",
    "href": "posts/ambisonic-reaper-1/index.html#footnotes",
    "title": "Mixage Ambisonique dans REAPER - Introduction",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nGerzon est également le premier à proposer une approche de la réverbération artificiel employant une matrice de réinjection (Feedback Delay Network).↩︎\nEn 3D, le nombre de canaux d’un flux ambisonique ce calcul grâce à la formule suivante : \\(N_{ch} = (N+1)^2\\), où \\(N\\) est l’ordre ambisonique↩︎"
  },
  {
    "objectID": "posts/ambisonic-reaper-1/ressources/too_much.html#conseils-de-mixage",
    "href": "posts/ambisonic-reaper-1/ressources/too_much.html#conseils-de-mixage",
    "title": "jeanlouppecquais.com",
    "section": "Conseils de mixage",
    "text": "Conseils de mixage\n\nLa question de l’ordre\nNous avons évoqué dans l’introduction la question de l’ambisonie d’ordre plus élevé ainsi que celle de son ordre. Tâchons maintenant d’expliciter ce concept et comment choisir ce paramètre en fonction de ses besoins.\nL’ambisonie constitue une forme d’échantillonnage. En audio, nous sommes généralement assez au fait de la question de l’échantillonnage lors du passage du domaine analogique au domaine numérique. Dans ce contexte, une plus grande résolution d’échantillonnage (ou fréquence d’échantillonnage) permet de représenter un spectre fréquentiel numérique plus important1. Si maintenant nous considérons un phénomène spatial et non plus temporel, nous pouvons appliquer une logique analogue : façon à un nombre de position dans l’espace en pratique illimité, il convient de limiter ce nombre de positions par un échantillonnage de l’espace.\nEn générale, cet échantillonnage est représenté par les haut-parleurs. Alors les mêmes règles que pour la conversion analogique-numérique s’appliquent : plus le nombre de haut-parleurs est grands, et plus sa répartition dans l’espace est homonogène, au mieux l’espace acoustique sera correctement échantillonné. 2\nL’ambisonie est une abstraction supplémentaire, dont l’idée repose sur la représentation d’un champ acoustique en un point où chaque source sonore serait idéalement placée sur la surface d’une sphère. Dès lors, l’ambisonie n’échantillonne pas des positions possibles dans l’espace mais plutôt les composantes d’une sphère, également appélées harmoniques sphériques. Cependant, la même logique s’applique, plus ces harmoniques sphériques sont nombreuses, plus notre champs sonore sera fidèlement capturé et réstitué.\nL’ordre ambisonique définit très exactement la résolution de notre champs ambisonique. Un ordre plus élevé a, dès lors, une plus grande résolution spatiale. Pour un ordre \\(N\\), on obtient \\((N+1)^2\\) harmoniques sphériques. Cela correspond aux nombres de canaux audio dans un flux ambisonique d’ordre \\(N\\).3\nIl convient maintenant d’établir une relation entre la résolution ambisonique (donc la valeur de l’ordre) et la densité d’échantillonnage de notre espace (nombre de haut-parleurs) ainsi que la position de ces échantillons (positions des haut-parleurs dans l’espace):\n\nPremièrement, comme l’ambisonie est l’échantillonnage d’un champs acoustique en un point, on attent à ce que l’ensemble de haut-parleurs prévu pour la réstitution sonore soit tous placés sur une sphère. 4\nDeuxièmement, on espère tout de même un échantionnage régulier de l’espace, même si nous avons évoqué ci-dessus que certains décodeurs permette de s’adapter à des arrangement de haut-parleurs irréguliers.\nTroisièment, il est fortement recommandé de toujours avoir plus de canaux d’enceintes que de canaux ambisonique. Par exemple, si je souhaite réaliser un mixage pour un ensemble de 32 haut-parleurs, alors je ne dois pas dépasser un flux ambisonique d’ordre 4 (dont le nombre de canaux est \\((4+1)^2 = 25\\)). On essaye donc d’avoir l’ordre ambisonique le plus élevé possible en respectant cette contrainte.\n\nMais alors, quid de l’agnosticité de l’ambisonique par rapport à notre arrangement de haut-parleurs ? Il est vrai que nous mettons ici en évidence une contrainte de nombre de haut-parleurs. Cependant nous avons deux façons de nous en extraire.\n\nPremièrement, un flux ambisonique d’ordre \\(N\\) peut être réduit à tous les ordre inférieurs. En effet, il suffit simplement d’ignorer les canaux audio transportant les informations relative aux ordres trop élevé pour notre cas d’usage. Ainsi, nous pouvons décoder de l’ambisonie d’ordre trois vers de la stéréo et troncant l’ambisonie à l’ordre un.\nDeuxième, il existe des algorithmes permettant d’upscaller l’ambisonie vers des ordre supérieurs.\n\nProposont maintenant une approche raisonnable de l’ambisonique.\nIl me semble que l’ambisonie d’ordre trois représente un bon équilibre entre résolution et flexibilité. Un flux ambisonique du troisième ordre contient seize canaux. Nous pouvons donc correctement restituer des arrangements de haut-parleurs constitués de moins de 25 haut-parleurs. Au délà, il sera préférable d’appliquer une algorithme d’upscalling afin d’étendre la résolution de notre mixage.\n\n\nStructurer sa console\n\n\n\nProposition de routage lors d’un mixage en ambisonie\n\n\nExaminons d’abord comment structurer le routage d’une session dans le contexte d’un mixage ambisonique. Dans le cadre d’une prise de son reposant sur de la multi-microphonie5, la première question qui vient est donc : faut-il encoder en ambisonie chaque microphone ?\nGénéralement, il est préférable d’encoder les différents instruments plutôt que leurs différentes sources d’enregistrement. Cela permet de conserver un flux audio mono ou stéréo le plus loin possible dans notre chemin du signal, ayant pour conséquence de simplifier le routage de notre console, de garder une bonne flexibilité de traitement, et, enfin, de limiter la ressource en calcules. Une basse, par exemple, est généralement captée à l’aide de quelques microphones et une DI. Il est alors judicieux de sommer d’abord l’ensemble de ces signaux pour former un bus dédié, le plus souvent monophonique, à l’instrument de basse. On peut ensuite encoder cet instrument.\nPour les instruments enregistrés grâce à un couple stéréophonique et complétés par des appoints6, on aura alors tendance à appliquer la même méthodologie : router l’ensemble des microphones dans un bus (ici stéréophonique) et encoder le signal stéréo en ambisonie.\nDans les rares cas où un instrument est enregistré à l’aide d’un microphone ambisonique et complété par des appoints, on pourrait alors, dans ce cas, encoder directement les appoints en ambisonie avant de former le bus instrument. Une prise de son ambisonique est souvent intéressante pour capturer l’acoustique du lieu. Dans ce cas, elle peut être considérée comme étant séparée du bus instrument.\nConcernant l’ajout de traitement et d’effets, il est alors vivement conseillé de réaliser un maximum de traitement avant l’encodage ambisonique. En effet, traiter 16 canaux est forcément beaucoup plus coûteux que d’en traiter deux (on pourrait se laisser dire huit fois plus coûteux.). De plus les plug-ins multicanaux sont rares, mais nous réaborderons ce point plus loin.\nConcrètement, on placera alors la majorité, voire l’intégralité des traitements avant l’encodeur ambisonique dans la chaîne d’effet de la piste. Du point de vue de l’optimisation des ressources, il semble que certaines heuristiques d’optimisation dans REAPER fonctionnent moins bien sur des pistes multicanales, même si les plugins eux-mêmes n’ont que deux canaux d’entrée/sortie. Pour résoudre ce problème, il convient alors de placer les effets préencodage dans un conteneur qui, lui, n’aura que deux canaux.\n\n\nGestion des effets\n\nÉgalisation et traitement linéaires et invariants temporellement de bus ambisonique\n\nL’égalisation de bus ambisonique ne pose pas de problème particulier. Il convient simplement d’appliquer la même correction à l’ensemble des canaux. Il faudra alors un outil supportant au moins 16 canaux pour de l’ordre trois. Le même raisonnement s’applique pour tous les traitements linéaires et invariants temporellement.\n\n\nCompression et traitement non linéaire de bus ambisonique\n\nLa question de la compression d’un bus ambisonique est moins simple. La difficulté principale est que la présence d’énergie dans un canal ambisonique n’implique pas une relation directe avec sa position dans l’espace. Dès lors, la compression différenciée des canaux est contre-indiquée pour éviter la dégradation de la spatialisation.\nOn trouve alors deux solutions. La première, et la plus simple sont de compresser l’ensemble des canaux du flux ambisonique en ne détectant l’enveloppe que sur le premier canal, dit W.\nL’autre solution consiste à décoder le signal ambisonique sur un t-design adéquat à l’ordre, puis de compresser le signal décodé, et, enfin, de réencoder le signal compressé.\nCertains compresseurs permettent aussi une compression par masquage spatial. On ne compresse ainsi que certaines zones de l’espace. Le compresseur de la suite IEM en est un bon exemple.\nPour les autres types de traitement non linéaire (saturation, limiteur, etc), on appliquera le même raisonnement que pour la compression.\n\n\nGestion du side-chain\n\nLe side-chain est une technique de compression permettant de compresser un signal à partir de l’enveloppe d’un autre signal. Le cas classique, popularisé par les musiques électroniques, est la compression de la basse par l’enveloppe du kick.\nOr, nos pistes ayant maintenant 16 canaux, il semble alors compliqué de pouvoir alimenter le circuit de détection d’un compresseur mono ou stéréo à partir d’un tel signal. Heureusement, nous avons une solution très simple à ce problème.\nLe premier canal de n’importe quel signal ambisonique, appelé généralement canal « W », correspond à une directivité omnidirectionnelle. En d’autres termes, ce canal représente le signal de notre instrument, indépendamment de la spatialisation que nous avons pu lui faire subir.\nPour réaliser une compression en side-chain, on pourra alors envoyer le canal W de notre piste de kick (donc le premier canal) dans le canal 17 de la piste de basse que l’on souhaite compresser.\n\n\nLa gestion des départs auxiliaires et des effets en parallèle\n\nAbordons maintenant la question des départs auxiliaires. Il convient de distinguer deux cas pratiques :\n\nAlimenter un effet mono ou stéréo, qui sera par la suite encodé en ambisonie, à partir d’un signal déjà encodé\nAlimenter un effet ambisonique à partir d’une piste ambisonique\n\nAvant de rentrer dans le détail, nous allons devoir détailler une astuce de mixage, également applicable en mixage stéréophonique.\nPlutôt que de directement router une piste vers un effet, type réverbération, on pourrait alors utiliser une piste intermédiaire, nous permettant de ce fait d’accéder à du traitement par envois dans un effet. En pratique, on commence par router la piste d’instrument dans une nouvelle piste, puis on place cette dernière dans une piste dossier. Sur ce dossier est instanciée la réverbération que l’on souhaite utiliser. Précisons par ailleurs qu’une piste ne consomme presque aucune ressource dans REAPER et que de telles manipulations de routage peuvent être largement simplifiées et automatisées par l’usage de scripts.\nRevenons au cas d’un mixage ambisonique.\nDans le premier cas, nous allons appliquer l’astuce déjà abordée précédemment. On route le canal W de notre flux ambisonique vers une nouvelle piste. Cette piste est alors placée dans un dossier qui contient l’effet mono ou stéréo. On encode ensuite cet effet en ambisonie.\nDans le second cas, nous allons alors envoyer les 16 canaux ambisoniques vers la nouvelle piste qui sera elle aussi placée dans un dossier qui contient l’effet. Dès lors, comme nous avons une piste intermédiaire, nous pouvons utiliser un effet ambisonique pour tourner la scène ambisonique de notre instrument, seulement pour l’entrée de l’effet. On peut alors imaginer avoir un instrument venant de la gauche et avoir sa réverbération provenant de la droite.\n\n\nRéverbération et synthèse d’espace\nUn outil clé en mixage est la réverbération afin de créer une impression de profondeur dans l’image sonore. Dans le cadre d’un mixage ambisonique, le plus simple est alors d’utiliser des réverbérations ambisoniques. Le problème est que celles-ci sont rares ! On pensera notamment à :\n\nL’IRCAM Verb de FLUX::\nL’AmbiVerb de NoiseMaker\nLa FDN Reverb de IEM\n\nFace à ce nombre limité d’outils, on est alors tenté d’exploiter des effets multicanaux, mais pas forcément ambisoniques.\n\nIntégrer une réverbération multicanal dans un mixage ambisonique\nOn trouve aujourd’hui un grand nombre de réverbérations multicanales, principalement dédiées au Dolby Atmos. Celles-ci supportent en général douze canaux d’entrées (7.1.4), voire seize (9.1.6). Il conviendra de toujours décoder le signal audio ambisonique avant d’attaque une réverbération multicanal. On réencode ensuite le signal de la réverbération.\nSi la réverbération employée propose un nombre de canaux suffisant et d’organisation spatial arbitraire, on préfèrera décodé le signal ambisonique vers des arrangements homogènes et uniformes (t-design par exemple).\n\n\nTransformer une réverbération stéréo en réverbération ambisonique\nLes réverbérations ambisoniques sont rares. Voici alors une petite astuce permettant de recycler des réverbérations stéréo. Bien sûr, il ne s’agit pas ici de réalisme acoustique, mais simplement de retrouver une sensation d’enveloppement. Voici l’ensemble de la chaîne de traitement de la piste de réverbération :\n\nOn commence par tronquer l’ordre ambisonique pour obtenir un signal du premier ordre.\nOn décode ce signal ambisonique sur un arrangement t-design 4\nOn place une instance de réverbération sur les canaux 1-2 et une autre sur les canaux 3-4\nOn applique un algorithme de décorrélation sur les canaux 3-4 (ou 1-2, peu importe).\nOn réencode le t-design 4 en ambisonie du premier ordre\nOn up-mix l’ambisonie d’ordre 1 vers l’ordre 3.\n\nExpliquons un peu plus en détail.\nTout d’abord, le choix du premier ordre est vivement conseillé pour simplifier le réglage des réverbérations. En effet, il faudra régler deux instances, et pas une ! Mieux vaut alors ne pas multiplier le nombre d’instances pour que le travail ne devienne pas trop fastidieux.\nL’arrangement t-design 4 contient quatre haut-parleurs, placés de façon homogène et uniforme. Il s’agit donc d’un cas idéal pour l’ambisonie.\nL’étape de décorrélation est nécessaire pour garantir une différence suffisante entre les canaux pour que l’on n’ait pas l’impression d’entendre deux fois la même réverbération, et donc perdre totalement la sensation d’espace.\nAprès le réencodage, une étape d’up-mixing permet de rejoindre notre ordre ambisonique initial.\n\nCe travail étant laborieux, on s’empressera de créer une « FX chain » dans REAPER pour ne pas avoir à répéter ce processus.\n\n\n\nQuels effets pour le traitement de signaux ambisoniques\nGlobalement, peu de constructeurs offrent leurs plug-ins en version multicanal. Particulièrement, l’ambisonie reste un marché de niche. Voici une liste non exhaustive de constructeurs particulièrement tournés vers cette technologie :\n\nIEM (open source & gratuit)\nSPARTA (open source & gratuit)\nFLUX::\nSound Particule\nNoise Maker\nBlue Ripple (principalement payant, onéreux et sans version de démo !)\nAudio Brewers (payant et sans version de démo !)\n\nCertains constructeurs prennent le parti de supporter un grand nombre de canaux, sans particulièrement se préoccuper de leur usage :\n\nREAPER (les principaux plug-ins supportent jusqu’à 128 canaux)\nMelda Production (64 canaux)\n\nBien que d’apparence disgracieuse, les plug-ins natifs de REAPER sont d’excellentes qualités. L’ensemble des fonctionnalités est généralement exhaustif sans être trop compliqué, et la qualité sonore est remarquable. Dans le cas du compresseur, il est possible de compresser l’ensemble des canaux en ne détectant l’enveloppe que sur le premier canal. Cette méthode est très utile en ambisonie.\nLes plugins de Melda Production peuvent également être une solution intéressante. Ils sont, cependant, souvent trop chargés en fonctionnalités de second ou troisième plan, et passent parfois à côté de choses élémentaires. L’UI est fastidieuse à naviguer et certains algorithmes sont franchement décevants (MAutoAlign). Mais pour autant, ils offrent un large panel d’outils dont la plupart s’adaptent bien au travail ambisonique, jusqu’au septième ordre. Particulièrement, leur MTurboReverb est une réussite !\nAussi important à mentionner, Jatin Chowdurry développe une excellente simulation à bande nommée ChowTapeModel et qui supporte un nombre arbitraire de canaux ! À tester urgemment.\nEnfin, la plupart des constructeurs offrant du multicanal le font dans le contexte de l’écosystème Dolby Atmos. Aujourd’hui, il n’est pas si rare de trouver des plug-ins gérant du 9.1.6, donc potentiellement les 16 canaux d’un ambisonie du troisième ordre (Pro Q 4 de Fabfilter, par exemple). Pour les plug-ins plafonnant à du 7.1.4, on pourra toujours passer par une étape de décodage et de réencodage ambisonique. Cette approche est parfaitement justifiable pour des effets, comme les délais et la réverbération. Pour un traitement sériel, la dégradation de l’image spatiale risque de ne pas en valoir la chandelle.\n\n\n\nLe monitoring\nÀ ce stage, nous ne sommes pas en mesure d’écouter notre mix. Pourquoi ? Un mixage ambisonique doit être décodé vers un arrangement de haut-parleur particulier afin de pouvoir être écouté. Entendons-nous, la question du décodage ambisonique est délicate et mériterais un article à part entière pour commencer à gratter la surface du sujet. Ici, nous nous contenterons de quelques recommandations.\n\nAmbisonie vers stéréophonie\nL’idée peut sembler étrange, pourtant, la stéréophonie reste le format de production dominant en audio. Le but ici n’est pas de retranscrire la sensation de spatialisation sur une paire de haut-parleurs, mais simplement de proposer une réduction robuste et efficace. Pour cela, l’UHJ est une solution intéressante. En effet, ce format ambisonique est un rematriçage de l’ambisonie du premier ordre. On a donc toujours quatre canaux, mais les deux premiers sont écoutables comme une stéréo classique. Encore mieux, il est possible de décoder une quadriphonie à partir de ces deux premiers canaux. On retrouve ici le principe du matriçage quadriphonique 4-2-4. Dolby s’en est d’ailleurs fortement inspiré pour créer son encoder-décodeur “Dobly Stereo” 7\nEn pratique, un convertisseur UHJ est disponible pour REAPER, au format JSFX 8 ici. C’est utilitaire est développé gratuitement par Bruce Wiggins.\n\n\nAmbisonie vers un arrangement quelconque\nPlusieurs outils permettent de décoder vers un arrangement de haut-parleur quelconque, on pense à AllRAD Decoder de la suite IEM et à AmbiDEC de SPARTA. Bien que cette discussion dépasse le cadre de cet article, il faut mentionner que l’utilisation d’un décodage AllRAD ou EPAD est souvent préférable, et ce, particulièrement lorsqu’on décode son signal ambisonique vers un arrangement de haut-parleurs qui n’est pas homogène.\n\n\nAmbisonie vers binaural\nLe monitoring d’une scène ambisonique en binaural est une option particulièrement intéressante, puisque l’on peut, en théorie, s’extraire de la contrainte du système de haut-parleurs. La faiblesse du rendu binaural réside souvent dans une dégradation des timbres. Cela dit, l’ambiBIN de SPARTA est un décodeur particulièrement bluffant en ce sens. Une option à explorer donc."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/ressources/too_much.html#conclusions",
    "href": "posts/ambisonic-reaper-1/ressources/too_much.html#conclusions",
    "title": "jeanlouppecquais.com",
    "section": "Conclusions",
    "text": "Conclusions\nBien que le Dolby Atmos soit souvent présenté comme une révolution dans le domaine de la spatialisation sonore, il présente plusieurs défauts notables qui remettent en question son adoption massive. Les limitations techniques, telles que la dépendance à des systèmes de diffusion spécifiques et hétérogènes, la variation de la perception de la largeur de la source, et l’absence de solutions satisfaisantes pour le traitement de groupes d’objets, sont autant de freins à son utilisation. De plus, la complexité accrue du mastering et la qualité discutable du rendu binaural ajoutent à ces préoccupations.\nEn revanche, l’ambisonie, une technologie plus ancienne, mais tout aussi prometteuse, offre des avantages similaires sans ces inconvénients. Grâce à des techniques de matriçage et à des décodeurs améliorés, l’ambisonie permet une flexibilité accrue et une meilleure interopérabilité des outils. Les suites de plug-ins comme IEM et SPARTA, qui sont distribuées gratuitement et open source, facilitent l’adoption de cette technologie.\nPour les ingénieurs du son souhaitant explorer la spatialisation sonore, l’ambisonie représente une alternative solide et éprouvée. En utilisant des logiciels comme REAPER, qui supportent un grand nombre de canaux, il est possible de réaliser des mixages ambisoniques de haute qualité tout en conservant les habitudes et techniques de mixage stéréophonique.\nAinsi, plutôt que de se laisser séduire par les promesses marketing du Dolby Atmos, il serait judicieux de se tourner vers l’ambisonie, une technologie qui a fait ses preuves et qui continue d’évoluer grâce aux contributions de la communauté scientifique et des passionnés du son."
  },
  {
    "objectID": "posts/ambisonic-reaper-1/ressources/too_much.html#footnotes",
    "href": "posts/ambisonic-reaper-1/ressources/too_much.html#footnotes",
    "title": "jeanlouppecquais.com",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nOn rappel que pour une fréquence d’échantillonnage \\(F_e\\), un système numérique peut correctement représenter des fréquences allant jusqu’à \\(\\frac{F_e}{2}\\)↩︎\nEn pratique, il convient d’appliquer aux représentations spatiales le même raisonnement que nous utilisons pour l’échantillonnage temporel. Tout comme nous limitons l’échantillonnage fréquentiel en conversion analogique-numérique en fonction de nos capacités auditives, nous devrions également adapter la résolution spatiale d’un échantillonnage de l’espace à nos capacités de localisation, qui ont aussi leurs propres limites physiologiques.↩︎\nCette formule s’applique pour de l’ambisonique 3D. En 2D, la relation entre l’ordre ambisonique et le nombre d’harmoniques sphériques/de canaux devient \\(2N+1\\).↩︎\nLors d’un déploiement in-situ, on peut s’adapter à la géométrie d’un lieu en appliquant des retards et des atténuation sur les haut-parleurs trop proches et ainsi les replacer virtuellement sur une sphère idéale.↩︎\nUn même instrument capté par ensemble de microphones de telle façon à échantillonner sa caractéristique sonore. Cette dernière est reconstituée en phase de mixage, par ajustement des équilibres de volumes entre les microphones après leur alignement en phase.↩︎\nDeux logiques s’appliquent ici. Soit, on considère un ensemble d’instruments, soit un unique instrument, mais généralement assez grand. Dans les deux cas, le couple de prise de son constitue la source de prise de son principale et les appoints ne sont joués que comme des compléments.↩︎\nOui, le système Left-Center-Right-Surround de Dobly se nomme bel et bien Dolby Stereo. On imagine alors toutes les confusions qui en ont résulté.↩︎\nFormat d’effet similaire au VST3 ou AudioUnit, mais dont le code est écrit en EEL, langage développé par… Cockos !↩︎"
  }
]